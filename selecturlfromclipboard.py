#!/usr/bin/python
# selecturlfromclipboard.py - snarf urls from clipboard
#
# This script uses BeautifulSoup to pull URLs and the descriptive text
# from any HTML that may exist in the clipboard.  If there's only
# plain text, then it'll use a crude regexp to pull the URLs from the
# text.  It then presents a list of URLs to the user, who then has an
# opportunity to launch one of the URLs in the default web browser via
# "xdg-open".
#
# As of 2023-08-14, this script was almost exclusively generated by
# Google Bard and ChatGPT after several prompts from robla

import re
from bs4 import BeautifulSoup
import subprocess

def get_clipboard_content():
    """Gets the content from the clipboard and determines its format."""
    process = subprocess.Popen(["wl-paste", "-l"], stdout=subprocess.PIPE)
    content_type = process.communicate()[0].decode("utf-8").strip()

    if "text/html" in content_type:
        process = subprocess.Popen(["wl-paste", "-t", "text/html"], stdout=subprocess.PIPE)
        clipboard_text = process.communicate()[0].decode("utf-8")
        return clipboard_text.strip(), "text/html"
    elif "text/plain" in content_type:
        process = subprocess.Popen(["wl-paste", "-t", "text/plain"], stdout=subprocess.PIPE)
        clipboard_text = process.communicate()[0].decode("utf-8")
        return clipboard_text.strip(), "text/plain"
    else:
        return "", ""

def parse_html(html):
    """Parses the given HTML and extracts the URLs with descriptive text."""
    soup = BeautifulSoup(html, "html.parser")
    url_info = []
    for a in soup.find_all("a"):
        url = a["href"]
        if url.startswith("http"):
            text = a.get_text()  # Get the descriptive text
            url_info.append((url, text))
    return url_info

def main():
    """The main function."""
    clipboard_content, content_type = get_clipboard_content()

    if content_type == "text/html":
        urls = parse_html(clipboard_content)
        print("Select a URL:")
        for index, (url, text) in enumerate(urls):
            print(f"  {index + 1}: {text} (<{url}>)")
        selected_url_index = int(input("Enter your selection: ")) - 1
        selected_url, _ = urls[selected_url_index]
    elif content_type == "text/plain":
        #urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', clipboard_content)
        urls = re.findall(r"https?://[A-Za-z0-9_\/\.\-\@\#\$\%\^\&\*\(\)]+", clipboard_content)
        print("Select a URL:")
        for index, url in enumerate(urls):
            print(f"  {index + 1}: {url}")
        selected_url_index = int(input("Enter your selection: ")) - 1
        selected_url = urls[selected_url_index]
    else:
        print("Unsupported content type.")

    open_url(selected_url)

def open_url(url):
    """Opens the given URL in the default web browser."""
    process = subprocess.Popen(["xdg-open", url])
    process.wait()

if __name__ == "__main__":
    main()
